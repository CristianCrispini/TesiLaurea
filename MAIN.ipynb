{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from cv2 import imread, imwrite\n",
    "from pyFusion.fusion import *\n",
    "from pyFusion.legacy.image_fusion_tool import Image_fusion_tool\n",
    "from pyFusion.models.vgg19 import VGG19\n",
    "from pyFusion.models.vgg16 import VGG16\n",
    "from pyFusion.models.squeezeNet import Squeeze\n",
    "from pyFusion import metrics\n",
    "from torch import device\n",
    "from torch.cuda import is_available\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Parse arguments\n",
    "images_path = ['images/T1-T2/t1.png', 'images/T1-T2/t2.png']\n",
    "output = 'results/MRI-CT/'\n",
    "\n",
    "# Read images\n",
    "input_images = []\n",
    "for image in images_path:\n",
    "    input_images.append(imread(image))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "device = device(\"cuda\" if is_available() else \"cpu\")\n",
    "model = VGG19(device)\n",
    "#model = VGG16(device)\n",
    "#model = Squeeze(device)\n",
    "\n",
    "FU = Fusion(input_images, model)\n",
    "fused_image = FU.fuse()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#imwrite(\"fusion\", fused_image.astype('uint8'))\n",
    "#plt.imshow(fused_image, cmap='gray')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def _pad_to(arr, shape):\n",
    "    \"\"\"Pad an array with trailing zeros to a given target shape.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : ndarray\n",
    "        The input array.\n",
    "    shape : tuple\n",
    "        The target shape.\n",
    "    Returns\n",
    "    -------\n",
    "    padded : ndarray\n",
    "        The padded array.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> _pad_to(np.ones((1, 1), dtype=int), (1, 3))\n",
    "    array([[1, 0, 0]])\n",
    "    \"\"\"\n",
    "    if not all(s >= i for s, i in zip(shape, arr.shape)):\n",
    "        raise ValueError(f'Target shape {shape} cannot be smaller than input'\n",
    "                         f'shape {arr.shape} along any axis.')\n",
    "    padding = [(0, s-i) for s, i in zip(shape, arr.shape)]\n",
    "    return np.pad(arr, pad_width=padding, mode='constant', constant_values=0)\n",
    "\n",
    "\n",
    "def normalized_mutual_information(image0, image1, *, bins=256):\n",
    "    r\"\"\"Compute the normalized mutual information (NMI).\n",
    "    The normalized mutual information of :math:`A` and :math:`B` is given by::\n",
    "    ..math::\n",
    "        Y(A, B) = \\frac{H(A) + H(B)}{H(A, B)}\n",
    "    where :math:`H(X) := - \\sum_{x \\in X}{x \\log x}` is the entropy.\n",
    "    It was proposed to be useful in registering images by Colin Studholme and\n",
    "    colleagues [1]_. It ranges from 1 (perfectly uncorrelated image values)\n",
    "    to 2 (perfectly correlated image values, whether positively or negatively).\n",
    "    Parameters\n",
    "    ----------\n",
    "    image0, image1 : ndarray\n",
    "        Images to be compared. The two input images must have the same number\n",
    "        of dimensions.\n",
    "    bins : int or sequence of int, optional\n",
    "        The number of bins along each axis of the joint histogram.\n",
    "    Returns\n",
    "    -------\n",
    "    nmi : float\n",
    "        The normalized mutual information between the two arrays, computed at\n",
    "        the granularity given by ``bins``. Higher NMI implies more similar\n",
    "        input images.\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the images don't have the same number of dimensions.\n",
    "    Notes\n",
    "    -----\n",
    "    If the two input images are not the same shape, the smaller image is padded\n",
    "    with zeros.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] C. Studholme, D.L.G. Hill, & D.J. Hawkes (1999). An overlap\n",
    "           invariant entropy measure of 3D medical image alignment.\n",
    "           Pattern Recognition 32(1):71-86\n",
    "           :DOI:`10.1016/S0031-3203(98)00091-0`\n",
    "    \"\"\"\n",
    "    if image0.ndim != image1.ndim:\n",
    "        raise ValueError(f'NMI requires images of same number of dimensions. '\n",
    "                         f'Got {image0.ndim}D for `image0` and '\n",
    "                         f'{image1.ndim}D for `image1`.')\n",
    "    if image0.shape != image1.shape:\n",
    "        max_shape = np.maximum(image0.shape, image1.shape)\n",
    "        padded0 = _pad_to(image0, max_shape)\n",
    "        padded1 = _pad_to(image1, max_shape)\n",
    "    else:\n",
    "        padded0, padded1 = image0, image1\n",
    "\n",
    "    hist, bin_edges = np.histogramdd(\n",
    "            [np.reshape(padded0, -1), np.reshape(padded1, -1)],\n",
    "            bins=bins,\n",
    "            density=True,\n",
    "            )\n",
    "\n",
    "    H0 = entropy(np.sum(hist, axis=0))\n",
    "    H1 = entropy(np.sum(hist, axis=1))\n",
    "    H01 = entropy(np.reshape(hist, -1))\n",
    "\n",
    "    return (H0 + H1) / H01\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aae5d2c5a6ba54df3fe7aa24bab40a051b8f850cb9383561333ce732ec88c927"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('VirtualEnv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}